{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "# Tree linearization\n",
    "def linearize(token, dependency_tree):\n",
    "\toutput = []\n",
    "\ttmp_dt = sorted(dependency_tree, key=lambda x : x[2])\n",
    "\tfor dt in tmp_dt:\n",
    "\t\ttmp = []\n",
    "\t\ttmp += [token[dt[2]-1]]\n",
    "\t\ttmp += [dt[0]]\n",
    "\t\ttmp += [dt[1]]\n",
    "\t\toutput.append(tmp)\n",
    "\treturn output\n",
    "\n",
    "def store_recursion(tree, n, L, o):\n",
    "    global global_i\n",
    "    if o == len(L):\n",
    "        n.data.append([L[j][2] for j in range(len(L))])\n",
    "        return\n",
    "    children_list = tree.children(n.identifier)\n",
    "    new_n = Node()\n",
    "    if children_list == []:\n",
    "        new_n = tree.create_node(tag=L[o][0], identifier=global_i+1, data=[L[o][1]], parent=n.identifier)\n",
    "        global_i += 1\n",
    "    else:\n",
    "        has_child = False\n",
    "        child_i = 0\n",
    "        while has_child == False and child_i < len(children_list):\n",
    "            if children_list[child_i].tag == L[o][0] and children_list[child_i].data[0] == L[o][1]:\n",
    "                has_child = True\n",
    "                new_n = children_list[child_i]\n",
    "                break\n",
    "            child_i += 1\n",
    "        if has_child == False:\n",
    "            new_n = tree.create_node(tag=L[o][0], identifier=global_i+1, data=[L[o][1]], parent=n.identifier)\n",
    "            global_i += 1\n",
    "    store_recursion(tree, new_n, L, o+1)\n",
    "\n",
    "# Return -1 if no such child, return child id otherwise\n",
    "def has_child(tree, n, Li):\n",
    "    children_list = tree.children(n)\n",
    "    child_id = -1\n",
    "    for i in range(len(children_list)):\n",
    "        if children_list[i].tag == Li[0] and children_list[i].data[0] == Li[1]:\n",
    "            child_id = children_list[i].identifier\n",
    "            return child_id\n",
    "    return child_id\n",
    "\n",
    "def is_compatible(L, S, P):\n",
    "    subseq = []\n",
    "    for p in P:\n",
    "        subseq.append(L[p][2])\n",
    "    return S == subseq\n",
    "\n",
    "def lookup_recursive(treeI, L, o, n, P, M):\n",
    "    for i in range(o, len(L)):\n",
    "        child_id = has_child(treeI, n, L[i])\n",
    "        if child_id != -1:\n",
    "            new_n = child_id\n",
    "            P.add(i)\n",
    "            if len(treeI.get_node(new_n).data) > 1:\n",
    "                for j in range(1, len(treeI.get_node(new_n).data)):\n",
    "                    S = treeI.get_node(new_n).data[j]\n",
    "                    if is_compatible(L, S, P):\n",
    "                        new_m = []\n",
    "                        for p in P:\n",
    "                            new_m.append(L[p][0])\n",
    "                        M.append(new_m)\n",
    "            lookup_recursive(treeI, L, o+1, new_n, P, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "################# Main Function #################\n",
    "#################################################\n",
    "nlp = StanfordCoreNLP(r'/home/xiaodan/Documents/stanford-corenlp-full-2018-02-27')   # Replace with your path\n",
    "tree = Tree()\n",
    "root = tree.create_node(tag='Root', identifier=0)#root node\n",
    "global_i = 0\n",
    "# Read from file\n",
    "for i in range(40):\n",
    "    filenamedir = \"/home/xiaodan/Downloads/rephrase/\"\n",
    "    filename = filenamedir+str(i)+'.txt'\n",
    "    f = open(filename, \"r\")\n",
    "\n",
    "    rawtesttext=f.read().strip().split('\\n')\n",
    "    line_count = len(rawtesttext)\n",
    "    # for line in f:\n",
    "    #     line_count += 1\n",
    "    #     rawtesttext.append(line.strip('\\n'))\n",
    "    f.close()\n",
    "\n",
    "    # Build dependency tree using the stanford tool\n",
    "    testtext = []\n",
    "    for text in rawtesttext:\n",
    "        #text = text[:-1]\n",
    "        token = nlp.word_tokenize(text)\n",
    "#         print(token)\n",
    "        dp = nlp.dependency_parse(text)\n",
    "#         print(dp)\n",
    "\n",
    "        output = linearize(token, dp)\n",
    "        testtext.append(output)\n",
    "#         print(output)\n",
    "#         print(\"_\"*30)\n",
    "    for text in testtext:\n",
    "        store_recursion(tree, root, text, 0)\n",
    "\n",
    "# Visualize the tree-trie\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Global_M=[]\n",
    "for i in range(40,50):\n",
    "    filenamedir = \"/home/xiaodan/Downloads/rephrase/\"\n",
    "    filename = filenamedir+str(i)+'.txt'\n",
    "    f = open(filename, \"r\")\n",
    "\n",
    "    rawtesttext=f.read().strip().split('\\n')\n",
    "    line_count = len(rawtesttext)\n",
    "    f.close()\n",
    "\n",
    "    # Build dependency tree using the stanford tool\n",
    "    testtext = []\n",
    "    for text in rawtesttext:\n",
    "        token = nlp.word_tokenize(text)\n",
    "        dp = nlp.dependency_parse(text)\n",
    "        output = linearize(token, dp)\n",
    "        testtext.append(output)\n",
    "    for text in testtext:\n",
    "        M = []\n",
    "        P = set()\n",
    "        lookup_recursive(tree, text, 0, 0, P, M)\n",
    "        Global_M.append(M)\n",
    "\n",
    "# Print the match results\n",
    "print(Global_M)\n",
    "nlp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
